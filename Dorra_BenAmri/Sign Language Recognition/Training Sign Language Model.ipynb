{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14158283,"sourceType":"datasetVersion","datasetId":9024206}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:37:42.629772Z","iopub.execute_input":"2025-12-15T02:37:42.629982Z","iopub.status.idle":"2025-12-15T02:38:08.078084Z","shell.execute_reply.started":"2025-12-15T02:37:42.629953Z","shell.execute_reply":"2025-12-15T02:38:08.077490Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"2025-12-15 02:37:49.030608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765766269.366686      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765766269.469193      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/data-csv-signe-language/dataset_keypoints.csv\")\n\nX = df[[f\"f{i}\" for i in range(63)]].values\ny = df[\"label\"].values\n\nprint(X.shape, y.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:38:08.079657Z","iopub.execute_input":"2025-12-15T02:38:08.080279Z","iopub.status.idle":"2025-12-15T02:38:08.210339Z","shell.execute_reply.started":"2025-12-15T02:38:08.080259Z","shell.execute_reply":"2025-12-15T02:38:08.209569Z"}},"outputs":[{"name":"stdout","text":"(3871, 63) (3871,)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"le = LabelEncoder()\ny_enc = le.fit_transform(y)\n\nnum_classes = len(le.classes_)\nprint(\"Number of classes:\", num_classes)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:38:08.211193Z","iopub.execute_input":"2025-12-15T02:38:08.211451Z","iopub.status.idle":"2025-12-15T02:38:08.216748Z","shell.execute_reply.started":"2025-12-15T02:38:08.211423Z","shell.execute_reply":"2025-12-15T02:38:08.215975Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 57\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pickle\nwith open(\"label_encoder.pkl\", \"wb\") as f:\n    pickle.dump(le, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:38:08.218031Z","iopub.execute_input":"2025-12-15T02:38:08.218289Z","iopub.status.idle":"2025-12-15T02:38:08.233608Z","shell.execute_reply.started":"2025-12-15T02:38:08.218271Z","shell.execute_reply":"2025-12-15T02:38:08.232817Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"X_train, X_temp, y_train, y_temp = train_test_split(\n    X, y_enc, test_size=0.3, stratify=y_enc, random_state=42\n)\n\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n)\n\nprint(X_train.shape, X_val.shape, X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:38:08.234284Z","iopub.execute_input":"2025-12-15T02:38:08.234442Z","iopub.status.idle":"2025-12-15T02:38:08.260986Z","shell.execute_reply.started":"2025-12-15T02:38:08.234429Z","shell.execute_reply":"2025-12-15T02:38:08.260308Z"}},"outputs":[{"name":"stdout","text":"(2709, 63) (581, 63) (581, 63)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from collections import Counter\n\ncounts = Counter(y_train)\n\nRARE_THRESHOLD = 30  # à ajuster\nrare_classes = [cls for cls, c in counts.items() if c < RARE_THRESHOLD]\n\nprint(\"Rare classes:\", [le.classes_[c] for c in rare_classes])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:38:08.261745Z","iopub.execute_input":"2025-12-15T02:38:08.261990Z","iopub.status.idle":"2025-12-15T02:38:08.266881Z","shell.execute_reply.started":"2025-12-15T02:38:08.261968Z","shell.execute_reply":"2025-12-15T02:38:08.266293Z"}},"outputs":[{"name":"stdout","text":"Rare classes: ['telvza', 'train', 'ta9ra', 'demande', 'louage', 'chabeb', 'karhba', 'thnin', 'ta3raf', 'sebt', 'assam', 'a7ad', '5adamet', 'mar7ba', 'métro', 'car', 'labes', 'bousta']\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass KeypointDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.tensor(X, dtype=torch.float32)\n        self.y = torch.tensor(y, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\ngan_data_idx = np.isin(y_train, rare_classes)\ngan_dataset = KeypointDataset(X_train[gan_data_idx], y_train[gan_data_idx])\n\ngan_loader = DataLoader(gan_dataset, batch_size=32, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:38:37.768963Z","iopub.execute_input":"2025-12-15T02:38:37.769608Z","iopub.status.idle":"2025-12-15T02:38:37.814832Z","shell.execute_reply.started":"2025-12-15T02:38:37.769582Z","shell.execute_reply":"2025-12-15T02:38:37.814283Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import torch.nn as nn\n\nclass Generator(nn.Module):\n    def __init__(self, noise_dim, num_classes, output_dim=63):\n        super().__init__()\n        self.label_emb = nn.Embedding(num_classes, num_classes)\n\n        self.net = nn.Sequential(\n            nn.Linear(noise_dim + num_classes, 128),\n            nn.ReLU(),\n            nn.Linear(128, 256),\n            nn.ReLU(),\n            nn.Linear(256, output_dim)\n        )\n\n    def forward(self, z, labels):\n        label_vec = self.label_emb(labels)\n        x = torch.cat([z, label_vec], dim=1)\n        return self.net(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:39:06.539978Z","iopub.execute_input":"2025-12-15T02:39:06.540562Z","iopub.status.idle":"2025-12-15T02:39:06.545535Z","shell.execute_reply.started":"2025-12-15T02:39:06.540537Z","shell.execute_reply":"2025-12-15T02:39:06.544951Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, num_classes, input_dim=63):\n        super().__init__()\n        self.label_emb = nn.Embedding(num_classes, num_classes)\n\n        self.net = nn.Sequential(\n            nn.Linear(input_dim + num_classes, 256),\n            nn.LeakyReLU(0.2),\n            nn.Linear(256, 128),\n            nn.LeakyReLU(0.2),\n            nn.Linear(128, 1),\n            nn.Sigmoid()\n        )\n\n    def forward(self, x, labels):\n        label_vec = self.label_emb(labels)\n        x = torch.cat([x, label_vec], dim=1)\n        return self.net(x)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:39:07.134042Z","iopub.execute_input":"2025-12-15T02:39:07.134656Z","iopub.status.idle":"2025-12-15T02:39:07.139565Z","shell.execute_reply.started":"2025-12-15T02:39:07.134628Z","shell.execute_reply":"2025-12-15T02:39:07.138926Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nG = Generator(noise_dim=50, num_classes=num_classes).to(device)\nD = Discriminator(num_classes=num_classes).to(device)\n\ncriterion = nn.BCELoss()\nopt_G = torch.optim.Adam(G.parameters(), lr=0.0002)\nopt_D = torch.optim.Adam(D.parameters(), lr=0.0002)\n\nEPOCHS = 200\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:39:07.829706Z","iopub.execute_input":"2025-12-15T02:39:07.830338Z","iopub.status.idle":"2025-12-15T02:39:11.308858Z","shell.execute_reply.started":"2025-12-15T02:39:07.830312Z","shell.execute_reply":"2025-12-15T02:39:11.308053Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    for real_x, labels in gan_loader:\n        real_x, labels = real_x.to(device), labels.to(device)\n        batch_size = real_x.size(0)\n\n        # ========== Train D ==========\n        z = torch.randn(batch_size, 50).to(device)\n        fake_x = G(z, labels)\n\n        real_loss = criterion(D(real_x, labels), torch.ones(batch_size, 1).to(device))\n        fake_loss = criterion(D(fake_x.detach(), labels), torch.zeros(batch_size, 1).to(device))\n\n        loss_D = real_loss + fake_loss\n        opt_D.zero_grad()\n        loss_D.backward()\n        opt_D.step()\n\n        # ========== Train G ==========\n        z = torch.randn(batch_size, 50).to(device)\n        fake_x = G(z, labels)\n        loss_G = criterion(D(fake_x, labels), torch.ones(batch_size, 1).to(device))\n\n        opt_G.zero_grad()\n        loss_G.backward()\n        opt_G.step()\n\n    if epoch % 20 == 0:\n        print(f\"Epoch {epoch} | D loss: {loss_D.item():.4f} | G loss: {loss_G.item():.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:39:11.310061Z","iopub.execute_input":"2025-12-15T02:39:11.310869Z","iopub.status.idle":"2025-12-15T02:39:24.744475Z","shell.execute_reply.started":"2025-12-15T02:39:11.310850Z","shell.execute_reply":"2025-12-15T02:39:24.743888Z"}},"outputs":[{"name":"stdout","text":"Epoch 0 | D loss: 1.2708 | G loss: 0.7072\nEpoch 20 | D loss: 0.8223 | G loss: 2.2517\nEpoch 40 | D loss: 0.3726 | G loss: 2.0128\nEpoch 60 | D loss: 0.8990 | G loss: 2.1022\nEpoch 80 | D loss: 0.5825 | G loss: 2.3849\nEpoch 100 | D loss: 0.8169 | G loss: 1.3309\nEpoch 120 | D loss: 0.6822 | G loss: 1.6627\nEpoch 140 | D loss: 1.0217 | G loss: 1.5934\nEpoch 160 | D loss: 0.4959 | G loss: 2.1412\nEpoch 180 | D loss: 0.7656 | G loss: 1.4080\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"def generate_samples(generator, label, n_samples):\n    generator.eval()\n    z = torch.randn(n_samples, 50).to(device)\n    labels = torch.tensor([label] * n_samples).to(device)\n    with torch.no_grad():\n        samples = generator(z, labels)\n    return samples.cpu().numpy()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:39:24.745535Z","iopub.execute_input":"2025-12-15T02:39:24.745755Z","iopub.status.idle":"2025-12-15T02:39:24.750015Z","shell.execute_reply.started":"2025-12-15T02:39:24.745731Z","shell.execute_reply":"2025-12-15T02:39:24.749263Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"X_synth = []\ny_synth = []\n\nTARGET_PER_CLASS = 50\n\nfor cls in rare_classes:\n    n_to_generate = TARGET_PER_CLASS - counts[cls]\n    if n_to_generate <= 0:\n        continue\n\n    samples = generate_samples(G, cls, n_to_generate)\n    X_synth.append(samples)\n    y_synth.extend([cls] * n_to_generate)\n\nX_synth = np.vstack(X_synth)\ny_synth = np.array(y_synth)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:39:24.750729Z","iopub.execute_input":"2025-12-15T02:39:24.750939Z","iopub.status.idle":"2025-12-15T02:39:24.785904Z","shell.execute_reply.started":"2025-12-15T02:39:24.750909Z","shell.execute_reply":"2025-12-15T02:39:24.785404Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"X_train_aug = np.vstack([X_train, X_synth])\ny_train_aug = np.concatenate([y_train, y_synth])\n\nprint(\"Before GAN:\", len(X_train))\nprint(\"After GAN:\", len(X_train_aug))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:39:24.786919Z","iopub.execute_input":"2025-12-15T02:39:24.787098Z","iopub.status.idle":"2025-12-15T02:39:24.792194Z","shell.execute_reply.started":"2025-12-15T02:39:24.787085Z","shell.execute_reply":"2025-12-15T02:39:24.791444Z"}},"outputs":[{"name":"stdout","text":"Before GAN: 2709\nAfter GAN: 3235\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"early_stop = EarlyStopping(\n    monitor=\"val_loss\",\n    patience=7,                # nb d'epochs sans amélioration\n    restore_best_weights=True,\n    verbose=1\n)\n\ncheckpoint = ModelCheckpoint(\n    \"best_tsl_mlp_model.h5\",\n    monitor=\"val_loss\",\n    save_best_only=True,\n    verbose=1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:42:09.811974Z","iopub.execute_input":"2025-12-15T02:42:09.812544Z","iopub.status.idle":"2025-12-15T02:42:09.816792Z","shell.execute_reply.started":"2025-12-15T02:42:09.812519Z","shell.execute_reply":"2025-12-15T02:42:09.816025Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\nmodel = models.Sequential([\n    layers.Input(shape=(63,)),\n    \n    layers.Dense(128, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    \n    layers.Dense(64, activation=\"relu\"),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    \n    layers.Dense(num_classes, activation=\"softmax\")\n])\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"sparse_categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)\n\nmodel.summary()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:42:10.199888Z","iopub.execute_input":"2025-12-15T02:42:10.200178Z","iopub.status.idle":"2025-12-15T02:42:10.260113Z","shell.execute_reply.started":"2025-12-15T02:42:10.200139Z","shell.execute_reply":"2025-12-15T02:42:10.259556Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_1\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m8,192\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57\u001b[0m)             │         \u001b[38;5;34m3,705\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,192</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,705</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,921\u001b[0m (81.72 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,921</span> (81.72 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,537\u001b[0m (80.22 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,537</span> (80.22 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n</pre>\n"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\nimport numpy as np\n\nclass_weights = compute_class_weight(\n    class_weight=\"balanced\",\n    classes=np.unique(y_train_aug),\n    y=y_train_aug\n)\n\nclass_weights = dict(enumerate(class_weights))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:42:10.538882Z","iopub.execute_input":"2025-12-15T02:42:10.539492Z","iopub.status.idle":"2025-12-15T02:42:10.544781Z","shell.execute_reply.started":"2025-12-15T02:42:10.539466Z","shell.execute_reply":"2025-12-15T02:42:10.544208Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"model.fit(\n    X_train_aug, y_train_aug,\n    validation_data=(X_val, y_val),\n    epochs=75,\n    batch_size=32,\n    callbacks=[early_stop, checkpoint],\n    class_weight=class_weights\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:42:10.885930Z","iopub.execute_input":"2025-12-15T02:42:10.886641Z","iopub.status.idle":"2025-12-15T02:42:43.882113Z","shell.execute_reply.started":"2025-12-15T02:42:10.886618Z","shell.execute_reply":"2025-12-15T02:42:43.881555Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/75\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1765766532.589492     130 service.cc:148] XLA service 0x7f54740079b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1765766532.590913     130 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1765766532.977667     130 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 69/102\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0421 - loss: 4.2759 ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1765766534.626645     130 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0576 - loss: 4.1412\nEpoch 1: val_loss improved from inf to 3.50336, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 26ms/step - accuracy: 0.0580 - loss: 4.1377 - val_accuracy: 0.1480 - val_loss: 3.5034\nEpoch 2/75\n\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2324 - loss: 2.9825\nEpoch 2: val_loss improved from 3.50336 to 3.01227, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.2353 - loss: 2.9719 - val_accuracy: 0.3632 - val_loss: 3.0123\nEpoch 3/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3538 - loss: 2.5482\nEpoch 3: val_loss improved from 3.01227 to 2.58823, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3557 - loss: 2.5379 - val_accuracy: 0.4544 - val_loss: 2.5882\nEpoch 4/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4257 - loss: 2.1654\nEpoch 4: val_loss improved from 2.58823 to 2.18218, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4265 - loss: 2.1599 - val_accuracy: 0.5112 - val_loss: 2.1822\nEpoch 5/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4731 - loss: 1.9752\nEpoch 5: val_loss improved from 2.18218 to 1.83496, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4744 - loss: 1.9666 - val_accuracy: 0.5800 - val_loss: 1.8350\nEpoch 6/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5033 - loss: 1.7838\nEpoch 6: val_loss improved from 1.83496 to 1.64093, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5063 - loss: 1.7784 - val_accuracy: 0.5783 - val_loss: 1.6409\nEpoch 7/75\n\u001b[1m 90/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5396 - loss: 1.7017\nEpoch 7: val_loss improved from 1.64093 to 1.53918, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5408 - loss: 1.6902 - val_accuracy: 0.6282 - val_loss: 1.5392\nEpoch 8/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5477 - loss: 1.5232\nEpoch 8: val_loss improved from 1.53918 to 1.40229, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5488 - loss: 1.5232 - val_accuracy: 0.6162 - val_loss: 1.4023\nEpoch 9/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5972 - loss: 1.4342\nEpoch 9: val_loss improved from 1.40229 to 1.34152, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5971 - loss: 1.4314 - val_accuracy: 0.6282 - val_loss: 1.3415\nEpoch 10/75\n\u001b[1m 81/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5976 - loss: 1.3734\nEpoch 10: val_loss improved from 1.34152 to 1.26805, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5966 - loss: 1.3754 - val_accuracy: 0.6575 - val_loss: 1.2681\nEpoch 11/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5872 - loss: 1.3798\nEpoch 11: val_loss improved from 1.26805 to 1.24318, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5878 - loss: 1.3768 - val_accuracy: 0.6558 - val_loss: 1.2432\nEpoch 12/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6061 - loss: 1.3536\nEpoch 12: val_loss improved from 1.24318 to 1.17341, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6074 - loss: 1.3440 - val_accuracy: 0.6644 - val_loss: 1.1734\nEpoch 13/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6447 - loss: 1.2191\nEpoch 13: val_loss improved from 1.17341 to 1.12272, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6442 - loss: 1.2176 - val_accuracy: 0.6799 - val_loss: 1.1227\nEpoch 14/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6347 - loss: 1.2167\nEpoch 14: val_loss improved from 1.12272 to 1.09282, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6359 - loss: 1.2124 - val_accuracy: 0.6867 - val_loss: 1.0928\nEpoch 15/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6497 - loss: 1.1090\nEpoch 15: val_loss improved from 1.09282 to 1.06525, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6501 - loss: 1.1084 - val_accuracy: 0.7108 - val_loss: 1.0652\nEpoch 16/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6309 - loss: 1.2339\nEpoch 16: val_loss did not improve from 1.06525\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6305 - loss: 1.2315 - val_accuracy: 0.6919 - val_loss: 1.0840\nEpoch 17/75\n\u001b[1m 90/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6480 - loss: 1.1119\nEpoch 17: val_loss improved from 1.06525 to 1.01293, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6486 - loss: 1.1109 - val_accuracy: 0.7091 - val_loss: 1.0129\nEpoch 18/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6526 - loss: 1.0842\nEpoch 18: val_loss did not improve from 1.01293\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6527 - loss: 1.0822 - val_accuracy: 0.6850 - val_loss: 1.0664\nEpoch 19/75\n\u001b[1m 90/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6522 - loss: 1.1189\nEpoch 19: val_loss improved from 1.01293 to 0.94782, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6532 - loss: 1.1118 - val_accuracy: 0.7177 - val_loss: 0.9478\nEpoch 20/75\n\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6814 - loss: 1.0205\nEpoch 20: val_loss did not improve from 0.94782\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6812 - loss: 1.0199 - val_accuracy: 0.7177 - val_loss: 0.9715\nEpoch 21/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6729 - loss: 1.0130\nEpoch 21: val_loss did not improve from 0.94782\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6727 - loss: 1.0133 - val_accuracy: 0.7005 - val_loss: 0.9820\nEpoch 22/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6822 - loss: 1.0370\nEpoch 22: val_loss improved from 0.94782 to 0.93846, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6823 - loss: 1.0334 - val_accuracy: 0.7263 - val_loss: 0.9385\nEpoch 23/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6891 - loss: 0.9633\nEpoch 23: val_loss did not improve from 0.93846\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6881 - loss: 0.9654 - val_accuracy: 0.7298 - val_loss: 0.9404\nEpoch 24/75\n\u001b[1m 90/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6788 - loss: 0.9510\nEpoch 24: val_loss improved from 0.93846 to 0.93682, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6799 - loss: 0.9535 - val_accuracy: 0.7384 - val_loss: 0.9368\nEpoch 25/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6914 - loss: 0.9511\nEpoch 25: val_loss improved from 0.93682 to 0.91152, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6914 - loss: 0.9520 - val_accuracy: 0.7453 - val_loss: 0.9115\nEpoch 26/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7084 - loss: 0.8976\nEpoch 26: val_loss improved from 0.91152 to 0.89106, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7079 - loss: 0.8994 - val_accuracy: 0.7487 - val_loss: 0.8911\nEpoch 27/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6787 - loss: 0.9946\nEpoch 27: val_loss improved from 0.89106 to 0.87233, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6788 - loss: 0.9919 - val_accuracy: 0.7298 - val_loss: 0.8723\nEpoch 28/75\n\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6680 - loss: 1.0389\nEpoch 28: val_loss did not improve from 0.87233\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6682 - loss: 1.0353 - val_accuracy: 0.7298 - val_loss: 0.8998\nEpoch 29/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6963 - loss: 0.9856\nEpoch 29: val_loss did not improve from 0.87233\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6960 - loss: 0.9820 - val_accuracy: 0.7573 - val_loss: 0.8845\nEpoch 30/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6810 - loss: 1.0276\nEpoch 30: val_loss did not improve from 0.87233\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6821 - loss: 1.0225 - val_accuracy: 0.7315 - val_loss: 0.8860\nEpoch 31/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6763 - loss: 0.9989\nEpoch 31: val_loss did not improve from 0.87233\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6763 - loss: 1.0002 - val_accuracy: 0.7435 - val_loss: 0.8855\nEpoch 32/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6798 - loss: 0.9303\nEpoch 32: val_loss did not improve from 0.87233\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6802 - loss: 0.9309 - val_accuracy: 0.7504 - val_loss: 0.8924\nEpoch 33/75\n\u001b[1m 83/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6795 - loss: 0.9905\nEpoch 33: val_loss improved from 0.87233 to 0.83959, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6827 - loss: 0.9762 - val_accuracy: 0.7608 - val_loss: 0.8396\nEpoch 34/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7130 - loss: 0.8997\nEpoch 34: val_loss did not improve from 0.83959\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7112 - loss: 0.8992 - val_accuracy: 0.7608 - val_loss: 0.8401\nEpoch 35/75\n\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7173 - loss: 0.8318\nEpoch 35: val_loss did not improve from 0.83959\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7160 - loss: 0.8355 - val_accuracy: 0.7435 - val_loss: 0.8426\nEpoch 36/75\n\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7021 - loss: 0.8712\nEpoch 36: val_loss did not improve from 0.83959\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7017 - loss: 0.8723 - val_accuracy: 0.7625 - val_loss: 0.8438\nEpoch 37/75\n\u001b[1m 88/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7015 - loss: 0.8725\nEpoch 37: val_loss improved from 0.83959 to 0.83788, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7033 - loss: 0.8693 - val_accuracy: 0.7694 - val_loss: 0.8379\nEpoch 38/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.7936\nEpoch 38: val_loss improved from 0.83788 to 0.80519, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7336 - loss: 0.7955 - val_accuracy: 0.7745 - val_loss: 0.8052\nEpoch 39/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.8060\nEpoch 39: val_loss did not improve from 0.80519\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.8104 - val_accuracy: 0.7522 - val_loss: 0.8295\nEpoch 40/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7086 - loss: 0.9534\nEpoch 40: val_loss did not improve from 0.80519\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7078 - loss: 0.9520 - val_accuracy: 0.7367 - val_loss: 0.8377\nEpoch 41/75\n\u001b[1m 89/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6703 - loss: 0.9281\nEpoch 41: val_loss did not improve from 0.80519\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6729 - loss: 0.9227 - val_accuracy: 0.7608 - val_loss: 0.8286\nEpoch 42/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7285 - loss: 0.8016\nEpoch 42: val_loss improved from 0.80519 to 0.80192, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7277 - loss: 0.8043 - val_accuracy: 0.7694 - val_loss: 0.8019\nEpoch 43/75\n\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7456 - loss: 0.7344\nEpoch 43: val_loss improved from 0.80192 to 0.76362, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.7371 - val_accuracy: 0.7814 - val_loss: 0.7636\nEpoch 44/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7188 - loss: 0.7960\nEpoch 44: val_loss did not improve from 0.76362\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7196 - loss: 0.7971 - val_accuracy: 0.7694 - val_loss: 0.7850\nEpoch 45/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7158 - loss: 0.8412\nEpoch 45: val_loss did not improve from 0.76362\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7159 - loss: 0.8393 - val_accuracy: 0.7728 - val_loss: 0.7794\nEpoch 46/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7288 - loss: 0.8392\nEpoch 46: val_loss did not improve from 0.76362\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7292 - loss: 0.8360 - val_accuracy: 0.7659 - val_loss: 0.8019\nEpoch 47/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7098 - loss: 0.8564\nEpoch 47: val_loss did not improve from 0.76362\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7093 - loss: 0.8573 - val_accuracy: 0.7676 - val_loss: 0.8159\nEpoch 48/75\n\u001b[1m 90/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.8361\nEpoch 48: val_loss did not improve from 0.76362\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7151 - loss: 0.8348 - val_accuracy: 0.7728 - val_loss: 0.7678\nEpoch 49/75\n\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7417 - loss: 0.7397\nEpoch 49: val_loss did not improve from 0.76362\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.7434 - val_accuracy: 0.7831 - val_loss: 0.7684\nEpoch 50/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7170 - loss: 0.8389\nEpoch 50: val_loss improved from 0.76362 to 0.74727, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7169 - loss: 0.8381 - val_accuracy: 0.7952 - val_loss: 0.7473\nEpoch 51/75\n\u001b[1m 86/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7525 - loss: 0.7464\nEpoch 51: val_loss did not improve from 0.74727\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7510 - loss: 0.7484 - val_accuracy: 0.7573 - val_loss: 0.7863\nEpoch 52/75\n\u001b[1m 86/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7385 - loss: 0.7838\nEpoch 52: val_loss improved from 0.74727 to 0.73627, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7380 - loss: 0.7828 - val_accuracy: 0.7797 - val_loss: 0.7363\nEpoch 53/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7572 - loss: 0.7548\nEpoch 53: val_loss improved from 0.73627 to 0.72577, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7567 - loss: 0.7538 - val_accuracy: 0.7935 - val_loss: 0.7258\nEpoch 54/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7489 - loss: 0.7504\nEpoch 54: val_loss improved from 0.72577 to 0.72508, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7480 - loss: 0.7515 - val_accuracy: 0.7952 - val_loss: 0.7251\nEpoch 55/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7405 - loss: 0.7267\nEpoch 55: val_loss did not improve from 0.72508\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7411 - loss: 0.7252 - val_accuracy: 0.7831 - val_loss: 0.7528\nEpoch 56/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7522 - loss: 0.7017\nEpoch 56: val_loss did not improve from 0.72508\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7509 - loss: 0.7064 - val_accuracy: 0.7952 - val_loss: 0.7271\nEpoch 57/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 0.7092\nEpoch 57: val_loss did not improve from 0.72508\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7419 - loss: 0.7103 - val_accuracy: 0.8158 - val_loss: 0.7333\nEpoch 58/75\n\u001b[1m 90/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7358 - loss: 0.7442\nEpoch 58: val_loss did not improve from 0.72508\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7357 - loss: 0.7465 - val_accuracy: 0.7831 - val_loss: 0.7325\nEpoch 59/75\n\u001b[1m 86/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7262 - loss: 0.7916\nEpoch 59: val_loss did not improve from 0.72508\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7276 - loss: 0.7871 - val_accuracy: 0.7745 - val_loss: 0.7498\nEpoch 60/75\n\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7226 - loss: 0.8434\nEpoch 60: val_loss did not improve from 0.72508\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7225 - loss: 0.8421 - val_accuracy: 0.7849 - val_loss: 0.7456\nEpoch 61/75\n\u001b[1m 89/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.7671\nEpoch 61: val_loss improved from 0.72508 to 0.71891, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7372 - loss: 0.7666 - val_accuracy: 0.7831 - val_loss: 0.7189\nEpoch 62/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.7412\nEpoch 62: val_loss improved from 0.71891 to 0.70701, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.7422 - val_accuracy: 0.7969 - val_loss: 0.7070\nEpoch 63/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7490 - loss: 0.7178\nEpoch 63: val_loss did not improve from 0.70701\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7488 - loss: 0.7209 - val_accuracy: 0.8003 - val_loss: 0.7123\nEpoch 64/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.7811\nEpoch 64: val_loss improved from 0.70701 to 0.69443, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7405 - loss: 0.7783 - val_accuracy: 0.8038 - val_loss: 0.6944\nEpoch 65/75\n\u001b[1m 88/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.6917\nEpoch 65: val_loss did not improve from 0.69443\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7408 - loss: 0.6987 - val_accuracy: 0.7745 - val_loss: 0.7345\nEpoch 66/75\n\u001b[1m 88/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7371 - loss: 0.7186\nEpoch 66: val_loss did not improve from 0.69443\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7369 - loss: 0.7230 - val_accuracy: 0.8107 - val_loss: 0.7145\nEpoch 67/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.7034\nEpoch 67: val_loss did not improve from 0.69443\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7373 - loss: 0.7032 - val_accuracy: 0.7900 - val_loss: 0.7000\nEpoch 68/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7461 - loss: 0.7637\nEpoch 68: val_loss improved from 0.69443 to 0.67957, saving model to best_tsl_mlp_model.h5\n","output_type":"stream"},{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7466 - loss: 0.7585 - val_accuracy: 0.8038 - val_loss: 0.6796\nEpoch 69/75\n\u001b[1m 90/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7441 - loss: 0.7405\nEpoch 69: val_loss did not improve from 0.67957\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7438 - loss: 0.7408 - val_accuracy: 0.7952 - val_loss: 0.6961\nEpoch 70/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7594 - loss: 0.7067\nEpoch 70: val_loss did not improve from 0.67957\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7590 - loss: 0.7071 - val_accuracy: 0.8003 - val_loss: 0.6925\nEpoch 71/75\n\u001b[1m 88/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7598 - loss: 0.6850\nEpoch 71: val_loss did not improve from 0.67957\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7604 - loss: 0.6858 - val_accuracy: 0.7917 - val_loss: 0.7109\nEpoch 72/75\n\u001b[1m 91/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.7705\nEpoch 72: val_loss did not improve from 0.67957\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.7680 - val_accuracy: 0.7900 - val_loss: 0.6950\nEpoch 73/75\n\u001b[1m 92/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7439 - loss: 0.7342\nEpoch 73: val_loss did not improve from 0.67957\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.7344 - val_accuracy: 0.7883 - val_loss: 0.6993\nEpoch 74/75\n\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7582 - loss: 0.6916\nEpoch 74: val_loss did not improve from 0.67957\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7575 - loss: 0.6915 - val_accuracy: 0.7935 - val_loss: 0.7010\nEpoch 75/75\n\u001b[1m 93/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.7054\nEpoch 75: val_loss did not improve from 0.67957\n\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.7041 - val_accuracy: 0.7883 - val_loss: 0.6983\nEpoch 75: early stopping\nRestoring model weights from the end of the best epoch: 68.\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7f54eaca31d0>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import classification_report\n\n# Charger le meilleur modèle sauvegardé\nbest_model = tf.keras.models.load_model(\"best_tsl_mlp_model.h5\")\n\ny_pred = np.argmax(best_model.predict(X_test), axis=1)\n\nprint(classification_report(\n    y_test,\n    y_pred,\n    target_names=le.classes_\n))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:42:48.162765Z","iopub.execute_input":"2025-12-15T02:42:48.163599Z","iopub.status.idle":"2025-12-15T02:42:48.686356Z","shell.execute_reply.started":"2025-12-15T02:42:48.163570Z","shell.execute_reply":"2025-12-15T02:42:48.685491Z"}},"outputs":[{"name":"stderr","text":"WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n              precision    recall  f1-score   support\n\n     3aslema       0.86      0.86      0.86         7\n       3ayla       0.70      0.78      0.74         9\n     5adamet       0.67      1.00      0.80         2\n     5al-3am       0.95      0.64      0.77        28\n        5mis       1.00      1.00      1.00         8\n         5ou       0.73      0.86      0.79        28\n        a7ad       0.71      0.83      0.77         6\n       assam       0.71      0.83      0.77         6\n     baladya       0.78      0.88      0.82        16\n       banka       0.67      0.89      0.76         9\n    barnamjk       0.93      1.00      0.96        13\n        bent       0.79      0.46      0.58        24\n         bou       0.77      0.95      0.85        21\n      bousta       0.00      0.00      0.00         4\n         car       0.57      0.80      0.67         5\n      chabeb       0.00      0.00      0.00         6\n          cv       1.00      1.00      1.00         8\n         dar       1.00      1.00      1.00        10\n     demande       1.00      1.00      1.00         5\n        eben       0.70      0.88      0.78        24\n        enti       0.82      1.00      0.90         9\n       erb3a       0.88      1.00      0.93         7\n         jad       0.76      0.68      0.72        19\n       jadda       0.67      0.33      0.44        12\n       jom3a       1.00      1.00      1.00         8\n      karhba       0.20      0.50      0.29         2\n       labes       1.00      1.00      1.00         3\n      louage       0.57      1.00      0.73         4\n       lyoum       1.00      1.00      1.00         7\n      ma7kma       1.00      0.67      0.80         6\n       mar2a       0.56      1.00      0.72        18\n      mar7ba       1.00      1.00      1.00         2\n   mostawsaf       0.88      0.58      0.70        12\n       métro       0.50      0.80      0.62         5\n     n3awnek       1.00      1.00      1.00        13\n    nekteblk       0.73      0.89      0.80         9\n         non       0.83      0.56      0.67         9\n         o5t       0.47      0.32      0.38        22\n          om       1.00      0.86      0.92         7\n         oui       1.00      0.77      0.87        13\n       radio       0.79      0.69      0.73        16\n      sbitar       0.88      1.00      0.93         7\n        se7a       0.85      0.61      0.71        18\n        sebt       0.62      1.00      0.77         5\n      siye7a       0.71      0.62      0.67         8\n        t7eb       1.00      1.00      1.00         7\n      ta3lim       1.00      1.00      1.00        12\n      ta3raf       1.00      1.00      1.00         5\n       ta9ra       1.00      0.83      0.91         6\n        taxi       1.00      0.93      0.96        14\n      telvza       0.75      0.75      0.75         4\n        tfol       1.00      0.82      0.90        11\n     tha9afa       1.00      1.00      1.00         9\n      thleth       0.56      1.00      0.71        10\n       thnin       1.00      0.83      0.91         6\n       train       1.00      0.83      0.91         6\n       wzara       0.92      1.00      0.96        11\n\n    accuracy                           0.80       581\n   macro avg       0.80      0.82      0.79       581\nweighted avg       0.81      0.80      0.79       581\n\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# modèle final\nbest_model.save(\"tsl_mlp_final.h5\")\n\n# encodeur des labels (déjà créé, rappel)\nimport pickle\nwith open(\"label_encoder.pkl\", \"wb\") as f:\n    pickle.dump(le, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:42:44.514387Z","iopub.execute_input":"2025-12-15T02:42:44.514670Z","iopub.status.idle":"2025-12-15T02:42:44.540399Z","shell.execute_reply.started":"2025-12-15T02:42:44.514651Z","shell.execute_reply":"2025-12-15T02:42:44.539842Z"}},"outputs":[{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# y_test et y_pred déjà calculés\ncm = confusion_matrix(y_test, y_pred)\n\nplt.figure(figsize=(18, 18))\nsns.heatmap(\n    cm,\n    xticklabels=le.classes_,\n    yticklabels=le.classes_,\n    cmap=\"Blues\",\n    square=True,\n    cbar=True\n)\n\nplt.xlabel(\"Predicted label\")\nplt.ylabel(\"True label\")\nplt.title(\"Confusion Matrix — Tunisian Sign Language (MLP)\")\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T02:42:55.490077Z","iopub.execute_input":"2025-12-15T02:42:55.490613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"confusions = []\n\nfor i in range(len(le.classes_)):\n    for j in range(len(le.classes_)):\n        if i != j and cm[i, j] > 0:\n            confusions.append((\n                le.classes_[i],\n                le.classes_[j],\n                cm[i, j]\n            ))\n\n# Trier par nombre d'erreurs\nconfusions = sorted(confusions, key=lambda x: x[2], reverse=True)\n\nconfusions[:15]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T01:01:18.331784Z","iopub.execute_input":"2025-12-15T01:01:18.332331Z","iopub.status.idle":"2025-12-15T01:01:18.342586Z","shell.execute_reply.started":"2025-12-15T01:01:18.332308Z","shell.execute_reply":"2025-12-15T01:01:18.341701Z"}},"outputs":[{"execution_count":70,"output_type":"execute_result","data":{"text/plain":"[('bent', 'eben', 5),\n ('o5t', '5ou', 5),\n ('o5t', 'mar2a', 5),\n ('5al-3am', 'sbitar', 4),\n ('5al-3am', 'thleth', 4),\n ('jadda', 'jad', 4),\n ('se7a', 'car', 4),\n ('5ou', 'o5t', 3),\n ('eben', 'bent', 3),\n ('mostawsaf', 'siye7a', 3),\n ('se7a', 'chabeb', 3),\n ('3ayla', 'radio', 2),\n ('5al-3am', 'baladya', 2),\n ('bent', 'mar2a', 2),\n ('bou', 'sebt', 2)]"},"metadata":{}}],"execution_count":70}]}