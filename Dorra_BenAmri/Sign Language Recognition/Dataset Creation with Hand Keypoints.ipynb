{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6453022,"sourceType":"datasetVersion","datasetId":3725712}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip -q install mediapipe opencv-python-headless pandas numpy tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T00:23:26.133386Z","iopub.execute_input":"2025-12-15T00:23:26.133864Z","iopub.status.idle":"2025-12-15T00:23:39.961088Z","shell.execute_reply.started":"2025-12-15T00:23:26.133843Z","shell.execute_reply":"2025-12-15T00:23:39.960197Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 4.25.8 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os, json\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\n\nimport mediapipe as mp\n\n# =========================\n# CONFIG\n# =========================\nDATA_ROOT = \"/kaggle/input/tunisian-sign-language-dataset/(First ever) Tunisian Sign Language Dataset/Data\"  # <-- change this\nOUTPUT_CSV = \"dataset_keypoints.csv\"\nOUTPUT_LABELS = \"labels.json\"\nBAD_IMAGES_LOG = \"bad_images.txt\"\n\nIMG_EXTS = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")\n\n\n# =========================\n# NORMALIZATION\n# =========================\ndef normalize_landmarks(landmarks_xyz: np.ndarray) -> np.ndarray:\n    \"\"\"\n    landmarks_xyz: shape (21, 3) in MediaPipe normalized coords [0..1] (x,y) and z ~ relative.\n    Steps:\n      1) center by wrist (index 0)\n      2) scale by distance wrist->index_mcp (index 5) to make it size-invariant\n    returns flattened vector shape (63,)\n    \"\"\"\n    pts = landmarks_xyz.copy()\n\n    wrist = pts[0]              # (x,y,z)\n    pts = pts - wrist           # center\n\n    ref = pts[5]                # index_mcp relative to wrist\n    scale = np.linalg.norm(ref[:2]) + 1e-8  # use x,y distance (more stable)\n    pts = pts / scale\n\n    return pts.reshape(-1)      # (63,)\n\n\n# =========================\n# MEDIAPIPE INIT\n# =========================\nmp_hands = mp.solutions.hands\nhands = mp_hands.Hands(\n    static_image_mode=True,     # for images\n    max_num_hands=1,            # 1 hand for now\n    model_complexity=1,\n    min_detection_confidence=0.5\n)\n\n\n# =========================\n# SCAN CLASSES\n# =========================\ndef list_classes_and_images(data_root: str):\n    \"\"\"\n    Finds all leaf folders (words) under themes.\n    Expected structure:\n      Data/\n        Demandes/\n          oui/ img...\n          non/ img...\n        Jours/\n          ...\n    Returns list of (label, img_path)\n    \"\"\"\n    samples = []\n    for theme in sorted(os.listdir(data_root)):\n        theme_path = os.path.join(data_root, theme)\n        if not os.path.isdir(theme_path):\n            continue\n\n        for label in sorted(os.listdir(theme_path)):\n            label_path = os.path.join(theme_path, label)\n            if not os.path.isdir(label_path):\n                continue\n\n            for fn in os.listdir(label_path):\n                if fn.lower().endswith(IMG_EXTS):\n                    samples.append((label, os.path.join(label_path, fn)))\n\n    return samples\n\n\nsamples = list_classes_and_images(DATA_ROOT)\nprint(\"Total images found:\", len(samples))\nprint(\"Example:\", samples[:3])\n\n\n# =========================\n# BUILD DATASET\n# =========================\nrows = []\nbad = []\n\nfor label, path in tqdm(samples):\n    img = cv2.imread(path)\n    if img is None:\n        bad.append(path)\n        continue\n\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    res = hands.process(img_rgb)\n\n    if not res.multi_hand_landmarks:\n        bad.append(path)\n        continue\n\n    lm = res.multi_hand_landmarks[0].landmark\n    landmarks_xyz = np.array([[p.x, p.y, p.z] for p in lm], dtype=np.float32)  # (21,3)\n\n    feat = normalize_landmarks(landmarks_xyz)  # (63,)\n    row = {\"label\": label, \"path\": path}\n    for i in range(63):\n        row[f\"f{i}\"] = float(feat[i])\n    rows.append(row)\n\ndf = pd.DataFrame(rows)\nprint(\"✅ Valid samples:\", len(df))\nprint(\"❌ Bad samples:\", len(bad))\ndisplay(df.head())\n\n\n# =========================\n# SAVE OUTPUTS\n# =========================\ndf.to_csv(OUTPUT_CSV, index=False)\n\nlabels = sorted(df[\"label\"].unique().tolist())\nwith open(OUTPUT_LABELS, \"w\", encoding=\"utf-8\") as f:\n    json.dump(labels, f, ensure_ascii=False, indent=2)\n\nwith open(BAD_IMAGES_LOG, \"w\", encoding=\"utf-8\") as f:\n    for p in bad:\n        f.write(p + \"\\n\")\n\nprint(\"Saved:\", OUTPUT_CSV, OUTPUT_LABELS, BAD_IMAGES_LOG)\nprint(\"Number of classes:\", len(labels))\nprint(\"Classes:\", labels[:20], \"...\" if len(labels) > 20 else \"\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T00:24:17.921585Z","iopub.execute_input":"2025-12-15T00:24:17.921999Z","iopub.status.idle":"2025-12-15T00:26:36.020820Z","shell.execute_reply.started":"2025-12-15T00:24:17.921964Z","shell.execute_reply":"2025-12-15T00:26:36.020073Z"}},"outputs":[{"name":"stderr","text":"2025-12-15 00:24:19.919337: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765758260.108822      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765758260.159073      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nINFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1765758272.216889     125 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1765758272.244352     125 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"},{"name":"stdout","text":"Total images found: 4423\nExample: [('3aslema', '/kaggle/input/tunisian-sign-language-dataset/(First ever) Tunisian Sign Language Dataset/Data/Demandes/3aslema/3aslema(1).jpg'), ('3aslema', '/kaggle/input/tunisian-sign-language-dataset/(First ever) Tunisian Sign Language Dataset/Data/Demandes/3aslema/3aslema(18).jpg'), ('3aslema', '/kaggle/input/tunisian-sign-language-dataset/(First ever) Tunisian Sign Language Dataset/Data/Demandes/3aslema/3aslema(33).jpg')]\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/4423 [00:00<?, ?it/s]W0000 00:00:1765758272.610819     124 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n100%|██████████| 4423/4423 [02:02<00:00, 35.97it/s]","output_type":"stream"},{"name":"stdout","text":"✅ Valid samples: 3871\n❌ Bad samples: 552\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"     label                                               path   f0   f1   f2  \\\n0  3aslema  /kaggle/input/tunisian-sign-language-dataset/(...  0.0  0.0  0.0   \n1  3aslema  /kaggle/input/tunisian-sign-language-dataset/(...  0.0  0.0  0.0   \n2  3aslema  /kaggle/input/tunisian-sign-language-dataset/(...  0.0  0.0  0.0   \n3  3aslema  /kaggle/input/tunisian-sign-language-dataset/(...  0.0  0.0  0.0   \n4  3aslema  /kaggle/input/tunisian-sign-language-dataset/(...  0.0  0.0  0.0   \n\n         f3        f4        f5        f6        f7  ...       f53       f54  \\\n0  0.258940 -0.555474 -0.070004  0.825894 -0.839742  ... -0.617440  1.478223   \n1 -0.312560 -0.357951 -0.113500 -0.729675 -0.532530  ... -0.188460 -1.120789   \n2  0.332884 -0.300327 -0.034415  0.787030 -0.340908  ... -0.137908  0.840609   \n3  0.345207 -0.301865 -0.040079  0.808136 -0.330393  ... -0.119071  0.839767   \n4  0.325659 -0.304260 -0.054396  0.794374 -0.347830  ... -0.113627  0.822273   \n\n        f55       f56       f57       f58       f59       f60       f61  \\\n0  0.401342 -0.597795  1.345782  0.356830 -0.453064  1.097425  0.371910   \n1  0.710180 -0.254590 -1.371996  0.749078 -0.289462 -1.576172  0.767450   \n2  0.864979 -0.145318  1.026104  0.952996 -0.105731  1.160058  1.020696   \n3  0.889445 -0.129981  1.030681  0.982355 -0.092482  1.170667  1.052416   \n4  0.868083 -0.117329  1.013579  0.954293 -0.082376  1.153289  1.022712   \n\n        f62  \n0 -0.358269  \n1 -0.308617  \n2 -0.070530  \n3 -0.058343  \n4 -0.052568  \n\n[5 rows x 65 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>path</th>\n      <th>f0</th>\n      <th>f1</th>\n      <th>f2</th>\n      <th>f3</th>\n      <th>f4</th>\n      <th>f5</th>\n      <th>f6</th>\n      <th>f7</th>\n      <th>...</th>\n      <th>f53</th>\n      <th>f54</th>\n      <th>f55</th>\n      <th>f56</th>\n      <th>f57</th>\n      <th>f58</th>\n      <th>f59</th>\n      <th>f60</th>\n      <th>f61</th>\n      <th>f62</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3aslema</td>\n      <td>/kaggle/input/tunisian-sign-language-dataset/(...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.258940</td>\n      <td>-0.555474</td>\n      <td>-0.070004</td>\n      <td>0.825894</td>\n      <td>-0.839742</td>\n      <td>...</td>\n      <td>-0.617440</td>\n      <td>1.478223</td>\n      <td>0.401342</td>\n      <td>-0.597795</td>\n      <td>1.345782</td>\n      <td>0.356830</td>\n      <td>-0.453064</td>\n      <td>1.097425</td>\n      <td>0.371910</td>\n      <td>-0.358269</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3aslema</td>\n      <td>/kaggle/input/tunisian-sign-language-dataset/(...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-0.312560</td>\n      <td>-0.357951</td>\n      <td>-0.113500</td>\n      <td>-0.729675</td>\n      <td>-0.532530</td>\n      <td>...</td>\n      <td>-0.188460</td>\n      <td>-1.120789</td>\n      <td>0.710180</td>\n      <td>-0.254590</td>\n      <td>-1.371996</td>\n      <td>0.749078</td>\n      <td>-0.289462</td>\n      <td>-1.576172</td>\n      <td>0.767450</td>\n      <td>-0.308617</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3aslema</td>\n      <td>/kaggle/input/tunisian-sign-language-dataset/(...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.332884</td>\n      <td>-0.300327</td>\n      <td>-0.034415</td>\n      <td>0.787030</td>\n      <td>-0.340908</td>\n      <td>...</td>\n      <td>-0.137908</td>\n      <td>0.840609</td>\n      <td>0.864979</td>\n      <td>-0.145318</td>\n      <td>1.026104</td>\n      <td>0.952996</td>\n      <td>-0.105731</td>\n      <td>1.160058</td>\n      <td>1.020696</td>\n      <td>-0.070530</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3aslema</td>\n      <td>/kaggle/input/tunisian-sign-language-dataset/(...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.345207</td>\n      <td>-0.301865</td>\n      <td>-0.040079</td>\n      <td>0.808136</td>\n      <td>-0.330393</td>\n      <td>...</td>\n      <td>-0.119071</td>\n      <td>0.839767</td>\n      <td>0.889445</td>\n      <td>-0.129981</td>\n      <td>1.030681</td>\n      <td>0.982355</td>\n      <td>-0.092482</td>\n      <td>1.170667</td>\n      <td>1.052416</td>\n      <td>-0.058343</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3aslema</td>\n      <td>/kaggle/input/tunisian-sign-language-dataset/(...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.325659</td>\n      <td>-0.304260</td>\n      <td>-0.054396</td>\n      <td>0.794374</td>\n      <td>-0.347830</td>\n      <td>...</td>\n      <td>-0.113627</td>\n      <td>0.822273</td>\n      <td>0.868083</td>\n      <td>-0.117329</td>\n      <td>1.013579</td>\n      <td>0.954293</td>\n      <td>-0.082376</td>\n      <td>1.153289</td>\n      <td>1.022712</td>\n      <td>-0.052568</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 65 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"Saved: dataset_keypoints.csv labels.json bad_images.txt\nNumber of classes: 57\nClasses: ['3aslema', '3ayla', '5adamet', '5al-3am', '5mis', '5ou', 'a7ad', 'assam', 'baladya', 'banka', 'barnamjk', 'bent', 'bou', 'bousta', 'car', 'chabeb', 'cv', 'dar', 'demande', 'eben'] ...\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv(\"dataset_keypoints.csv\")\nprint(df.shape)                 # (N, 65) -> label + path + 63 features\nprint(df[\"label\"].nunique())    # nb de mots\nprint(df[\"label\"].value_counts().head(10))  # distribution\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T00:28:01.465030Z","iopub.execute_input":"2025-12-15T00:28:01.465698Z","iopub.status.idle":"2025-12-15T00:28:01.543346Z","shell.execute_reply.started":"2025-12-15T00:28:01.465673Z","shell.execute_reply":"2025-12-15T00:28:01.542775Z"}},"outputs":[{"name":"stdout","text":"(3871, 65)\n57\nlabel\n5al-3am    184\n5ou        183\neben       159\nbent       156\no5t        143\nbou        137\njad        131\nmar2a      124\nse7a       116\nbaladya    109\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3}]}