import os
import chromadb
from chromadb.utils import embedding_functions
from langchain.text_splitter import RecursiveCharacterTextSplitter

# ===========================================================
# üßπ 1Ô∏è‚É£ Fonction de nettoyage du texte brut
# ===========================================================
def clean_text(text: str) -> str:
    """
    Nettoie le texte m√©dical : supprime espaces inutiles, retours √† la ligne
    et caract√®res sp√©ciaux redondants.
    """
    text = text.replace("\t", " ").replace("\r", " ")
    while "  " in text:
        text = text.replace("  ", " ")
    return text.strip()

# ===========================================================
# üß© 2Ô∏è‚É£ Fonction principale : cr√©ation des collections Chroma
# ===========================================================
def build_collection(specialty: str):
    print(f"\nüìò Construction de la collection pour {specialty} ...")

    # ---- 1. Initialiser ChromaDB local
    client = chromadb.PersistentClient(path="chroma_db")

    # ---- 2. D√©finir la fonction d‚Äôembedding
    embedder = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="sentence-transformers/all-MiniLM-L6-v2"
    )

    # ---- 3. Cr√©er ou r√©cup√©rer la collection
    collection = client.get_or_create_collection(
        name=specialty,
        embedding_function=embedder
    )

    # ---- 4. Charger le texte brut de la sp√©cialit√©
    data_path = f"agents/{specialty}/data/{specialty}_docs.txt"
    if not os.path.exists(data_path):
        print(f"‚ö†Ô∏è  Fichier introuvable : {data_path}")
        return

    with open(data_path, "r", encoding="utf-8") as f:
        raw_text = f.read()

    # ---- 5. Nettoyer le texte
    clean = clean_text(raw_text)

    # ---- 6. D√©coupage avanc√© avec RecursiveCharacterTextSplitter
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=200,
        chunk_overlap=100,
        separators=["\n\n", "\n", "(?<=\. )", " ", ""],
        length_function=len
    )
    chunks = text_splitter.split_text(clean)

    print(f"‚Üí {len(chunks)} chunks g√©n√©r√©s pour {specialty}")

    # ---- 7. Ajouter les chunks dans Chroma
    collection.add(
        documents=chunks,
        ids=[f"{specialty}_{i}" for i in range(len(chunks))],
        metadatas=[{"specialty": specialty, "chunk": i} for i in range(len(chunks))]
    )

    print(f"‚úÖ Collection '{specialty}' mise √† jour ({len(chunks)} chunks)")

# ===========================================================
# üöÄ 3Ô∏è‚É£ Point d‚Äôentr√©e principal
# ===========================================================
if __name__ == "__main__":
    # Cr√©er le dossier Chroma s‚Äôil n‚Äôexiste pas
    os.makedirs("chroma_db", exist_ok=True)

    # Liste des sp√©cialit√©s √† indexer
    specialties = ["cardio", "neuro"]

    for sp in specialties:
        build_collection(sp)

    print("\nüéâ Indexation termin√©e avec succ√®s !")
